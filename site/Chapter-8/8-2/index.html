
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="《强化学习的数学原理》的课程笔记">
      
      
        <meta name="author" content="Guangyu">
      
      
        <link rel="canonical" href="https://wgyhhhh.github.io/Mathematical-Foundations-of-Reinforcement-Learning-Notes/Chapter-8/8-2/">
      
      
        <link rel="prev" href="../8-1/">
      
      
        <link rel="next" href="../8-3/">
      
      <link rel="icon" href="../../img/favicon-96x96.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.1.18">
    
    
      
        <title>8.2-基于值函数的时序差分算法:状态值估计 - 强化学习课程笔记</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.26e3688c.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ecc896b0.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/misc.css">
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="green">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../.." title="强化学习课程笔记" class="md-header__button md-logo" aria-label="强化学习课程笔记" data-md-component="logo">
      
  <img src="../../img/logo.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            强化学习课程笔记
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              8.2-基于值函数的时序差分算法:状态值估计
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
          
            
            
            
            <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="green"  aria-label="明亮主题"  type="radio" name="__palette" id="__palette_1">
            
              <label class="md-header__button md-icon" title="明亮主题" for="__palette_2" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
              </label>
            
          
            
            
            
            <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="yellow"  aria-label="暗黑主题"  type="radio" name="__palette" id="__palette_2">
            
              <label class="md-header__button md-icon" title="暗黑主题" for="__palette_1" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
              </label>
            
          
        </form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/wgyhhhh/Mathematical-Foundations-of-Reinforcement-Learning-Notes" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    wgyhhhh/Mathematical-Foundations-of-Reinforcement-Learning-Notes
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        主页
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../Box/intro/" class="md-tabs__link">
        Box
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../Chapter-1/intro/" class="md-tabs__link">
        第一章
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../Chapter-2/intro/" class="md-tabs__link">
        第二章
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../Chapter-3/intro/" class="md-tabs__link">
        第三章
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../Chapter-4/intro/" class="md-tabs__link">
        第四章
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../Chapter-5/intro/" class="md-tabs__link">
        第五章
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../Chapter-6/intro/" class="md-tabs__link">
        第六章
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../Chapter-7/intro/" class="md-tabs__link">
        第七章
      </a>
    </li>
  

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="../intro/" class="md-tabs__link md-tabs__link--active">
        第八章
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../Chapter-9/intro/" class="md-tabs__link">
        第九章
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../Chapter-10/intro/" class="md-tabs__link">
        第十章
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../Appendix/1/" class="md-tabs__link">
        附录
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="强化学习课程笔记" class="md-nav__button md-logo" aria-label="强化学习课程笔记" data-md-component="logo">
      
  <img src="../../img/logo.jpg" alt="logo">

    </a>
    强化学习课程笔记
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/wgyhhhh/Mathematical-Foundations-of-Reinforcement-Learning-Notes" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    wgyhhhh/Mathematical-Foundations-of-Reinforcement-Learning-Notes
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1" >
      
      
        
          
            
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../..">主页</a>
          
            <label for="__nav_1">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          主页
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Preface1/" class="md-nav__link">
        引言
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
      
      
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
          Box
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Box
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Box/intro/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Box/Box-7-1/" class="md-nav__link">
        7.1:TD算法的推导
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Box/Box-7-4/" class="md-nav__link">
        7.4:期望Sarsa算法
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
          第一章
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          第一章
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-1/intro/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-1/1-1/" class="md-nav__link">
        1.1-网格世界
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-1/1-2/" class="md-nav__link">
        1.2-状态和行动
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-1/1-3/" class="md-nav__link">
        1.3-状态转移
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-1/1-4/" class="md-nav__link">
        1.4-策略
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-1/1-5/" class="md-nav__link">
        1.5-奖励
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-1/1-6/" class="md-nav__link">
        1.6-轨迹、回报、回合
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-1/1-7/" class="md-nav__link">
        1.7-马尔科夫决策过程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-1/1-8/" class="md-nav__link">
        1.8-总结
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
          第二章
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          第二章
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-2/intro/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-2/2-1/" class="md-nav__link">
        2.1-为什么回报很重要?
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-2/2-2/" class="md-nav__link">
        2.2-如何计算回报?
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-2/2-3/" class="md-nav__link">
        2.3-状态值
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-2/2-4/" class="md-nav__link">
        2.4-贝尔曼方程
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-2/2-5/" class="md-nav__link">
        2.5-贝尔曼方程的例子
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-2/2-6/" class="md-nav__link">
        2.6-贝尔曼方程的矩阵形式
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-2/2-7/" class="md-nav__link">
        2.7-求解状态值
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-2/2-8/" class="md-nav__link">
        2.8-行动值
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-2/2-9/" class="md-nav__link">
        2.9-总结
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
          第三章
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          第三章
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-3/intro/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-3/3-1/" class="md-nav__link">
        3.1-如何改进策略
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-3/3-2/" class="md-nav__link">
        3.2-最优状态值和最优策略
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-3/3-3/" class="md-nav__link">
        3.3-贝尔曼最优公式
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-3/3-4/" class="md-nav__link">
        3.4-从贝尔曼最优公式中求解最优策略
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-3/3-5/" class="md-nav__link">
        3.5-影响最优策略的因素
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-3/3-6/" class="md-nav__link">
        3.6-总结
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
      
      
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
          第四章
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          第四章
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-4/intro/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-4/4-1/" class="md-nav__link">
        4.1-值迭代
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-4/4-2/" class="md-nav__link">
        4.2-策略迭代
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-4/4-3/" class="md-nav__link">
        4.3-截断策略迭代
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-4/4-4/" class="md-nav__link">
        4.4-总结
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7" >
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
          第五章
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          第五章
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-5/intro/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-5/5-1/" class="md-nav__link">
        5.1-启发示例:期望值估计
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-5/5-2/" class="md-nav__link">
        5.2-MC Basic:最简单的基于蒙特卡洛的算法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-5/5-3/" class="md-nav__link">
        5.3-MC Exploring Starts算法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-5/5-4/" class="md-nav__link">
        5.4-MC-Greedy算法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-5/5-5/" class="md-nav__link">
        5.5-探索与利用:以Greedy策略为例
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-5/5-6/" class="md-nav__link">
        5.6-总结
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_8" >
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
          第六章
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_8">
          <span class="md-nav__icon md-icon"></span>
          第六章
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-6/intro/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-6/6-1/" class="md-nav__link">
        6.1-启发示例:期望值估计
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-6/6-2/" class="md-nav__link">
        6.2-罗宾斯-门罗算法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-6/6-3/" class="md-nav__link">
        6.3-Dvoretzky定理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-6/6-4/" class="md-nav__link">
        6.4-随机梯度下降
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-6/6-5/" class="md-nav__link">
        6.5-总结
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_9" >
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
          第七章
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_9">
          <span class="md-nav__icon md-icon"></span>
          第七章
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-7/intro/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-7/7-1/" class="md-nav__link">
        7.1-状态值估计:时序差分算法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-7/7-2/" class="md-nav__link">
        7.2-行动值估计:Sarsa
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-7/7-3/" class="md-nav__link">
        7.3-行动值估计:n步Sarsa
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-7/7-4/" class="md-nav__link">
        7.4-最优行动值估计:Q-Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-7/7-5/" class="md-nav__link">
        7.5-时序差分算法的统一框架
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-7/7-6/" class="md-nav__link">
        7.6-总结
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10" checked>
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
          第八章
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_10">
          <span class="md-nav__icon md-icon"></span>
          第八章
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../intro/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../8-1/" class="md-nav__link">
        8.1-价值表示:从表格到函数
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          8.2-基于值函数的时序差分算法:状态值估计
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        8.2-基于值函数的时序差分算法:状态值估计
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    基于值函数的时序差分算法: 状态值估计
  </a>
  
    <nav class="md-nav" aria-label="基于值函数的时序差分算法: 状态值估计">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#821" class="md-nav__link">
    8.2.1 目标函数
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#822" class="md-nav__link">
    8.2.2 优化算法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#823" class="md-nav__link">
    8.2.3 函数近似器的选择
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#824" class="md-nav__link">
    8.2.4 例子
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#825" class="md-nav__link">
    8.2.5 理论分析
  </a>
  
    <nav class="md-nav" aria-label="8.2.5 理论分析">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    收敛性分析
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#td" class="md-nav__link">
    TD学习最小化投影贝尔曼误差
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#td_1" class="md-nav__link">
    最小二乘TD
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../8-3/" class="md-nav__link">
        8.3-基于值函数的时序差分算法:行动值估计
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../8-4/" class="md-nav__link">
        8.4-深度Q-learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../8-5/" class="md-nav__link">
        8.5-总结
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_11" >
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_11" id="__nav_11_label" tabindex="0">
          第九章
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_11">
          <span class="md-nav__icon md-icon"></span>
          第九章
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-9/intro/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-9/9-1/" class="md-nav__link">
        9.1-策略表示:从表格到函数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-9/9-2/" class="md-nav__link">
        9.2-目标函数:定义最优策略
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-9/9-3/" class="md-nav__link">
        9.3-目标函数的梯度
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-9/9-4/" class="md-nav__link">
        9.4-蒙特卡洛策略梯度
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-9/9-5/" class="md-nav__link">
        9.5-总结
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_12" >
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_12" id="__nav_12_label" tabindex="0">
          第十章
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_12_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_12">
          <span class="md-nav__icon md-icon"></span>
          第十章
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-10/intro/" class="md-nav__link">
        介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-10/10-1/" class="md-nav__link">
        10.1-最简单的演员-评论性方法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-10/10-2/" class="md-nav__link">
        10.2-优势演员-评论性方法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-10/10-3/" class="md-nav__link">
        10.3-异策略演员-评论性方法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-10/10-4/" class="md-nav__link">
        10.4-确定性演员-评论性方法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Chapter-10/10-5/" class="md-nav__link">
        10.5-总结
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_13" >
      
      
        
          
        
      
      
        <label class="md-nav__link" for="__nav_13" id="__nav_13_label" tabindex="0">
          附录
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_13_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_13">
          <span class="md-nav__icon md-icon"></span>
          附录
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Appendix/1/" class="md-nav__link">
        术语
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    基于值函数的时序差分算法: 状态值估计
  </a>
  
    <nav class="md-nav" aria-label="基于值函数的时序差分算法: 状态值估计">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#821" class="md-nav__link">
    8.2.1 目标函数
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#822" class="md-nav__link">
    8.2.2 优化算法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#823" class="md-nav__link">
    8.2.3 函数近似器的选择
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#824" class="md-nav__link">
    8.2.4 例子
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#825" class="md-nav__link">
    8.2.5 理论分析
  </a>
  
    <nav class="md-nav" aria-label="8.2.5 理论分析">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    收敛性分析
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#td" class="md-nav__link">
    TD学习最小化投影贝尔曼误差
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#td_1" class="md-nav__link">
    最小二乘TD
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/wgyhhhh/Mathematical-Foundations-of-Reinforcement-Learning-Notes/edit/master/docs/Chapter-8/8-2.md" title="编辑此页" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4v-2m10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1 2.1 2.1Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/wgyhhhh/Mathematical-Foundations-of-Reinforcement-Learning-Notes/raw/master/docs/Chapter-8/8-2.md" title="查看本页的源代码" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.15 8.15 0 0 1-1.23-2Z"/></svg>
    </a>
  


  <h1>8.2-基于值函数的时序差分算法:状态值估计</h1>

<h2 id="_1">基于值函数的时序差分算法: 状态值估计<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<p>本节将阐述如何将函数近似方法整合至时序差分(TD)学习框架中，用于估计给定策略的状态值。该算法将在<span class="arithmatex">\(8.3\)</span>节进一步扩展至行动值与最优策略的学习。</p>
<p>本节包含多个子章节及大量连贯内容。建议在深入细节前先整体回顾内容。</p>
<ul>
<li>
<p>函数近似方法被表述为一个优化问题。该问题的目标函数在第<span class="arithmatex">\(8.2.1\)</span>节中给出。用于优化该目标函数的TD学习算法将在第<span class="arithmatex">\(8.2.2\)</span>节中介绍。</p>
</li>
<li>
<p>为应用TD学习算法，我们需要选择合适的特征向量。<span class="arithmatex">\(8.2.3\)</span>节将讨论该问题。</p>
</li>
<li>
<p><span class="arithmatex">\(8.2.4\)</span>节通过示例演示了TD算法及不同特征向量的影响。</p>
</li>
<li>
<p>关于TD算法的理论分析详见第<span class="arithmatex">\(8.2.5\)</span>节。该小节数学推导较为密集，读者可根据兴趣选择性阅读。</p>
</li>
</ul>
<h3 id="821">8.2.1 目标函数<a class="headerlink" href="#821" title="Permanent link">&para;</a></h3>
<p>设<span class="arithmatex">\(v_\pi(s)\)</span>与<span class="arithmatex">\(\hat{v}(s, w)\)</span>分别表示状态<span class="arithmatex">\(s \in S\)</span>的真实状态值和近似状态值。待求解的问题是找到最优参数<span class="arithmatex">\(w\)</span>，使得对于所有状态<span class="arithmatex">\(s\)</span>，<span class="arithmatex">\(\hat{v}(s, w)\)</span>能最佳近似<span class="arithmatex">\(v_\pi(s)\)</span>。具体而言，目标函数为</p>
<div class="arithmatex">\[J(w)=\mathbb{E}[(v_\pi(S)-\hat{v}(S,w))^2],\tag{8.3}\]</div>
<p>其中期望值是关于随机变量<span class="arithmatex">\(S \in \mathcal{S}\)</span>计算的。虽然<span class="arithmatex">\(S\)</span>是一个随机变量，但其概率分布是什么？这个问题对于理解该目标函数至关重要。定义<span class="arithmatex">\(S\)</span>的概率分布有以下几种方式。</p>
<ul>
<li>
<p><strong>第一种方法是采用均匀分布</strong>。即通过将每个状态的概率设为<span class="arithmatex">\(1/n\)</span>，将所有状态视为同等重要。此时，<span class="arithmatex">\((8.3)\)</span>中的目标函数变为</p>
<div class="arithmatex">\[J(w)=\frac{1}{n}\sum_{s\in\mathcal{S}}(v_\pi(s)-\hat{v}(s,w))^2,\tag{8.4}\]</div>
<p>这是所有状态近似误差的平均值。然而，这种方法没有考虑给定策略下马尔可夫过程的真实动态特性。由于某些状态可能很少被策略访问到，将所有状态视为同等重要并不合理。</p>
</li>
<li>
<p><strong>第二种方法(本章重点)是利用稳态分布(stationary distribution)</strong>。稳态分布描述了马尔可夫决策过程的长期行为(long-run behavior)；具体而言，当智能体执行给定策略足够长时间后，其处于任意状态的概率均可由该稳态分布表征。感兴趣的读者可参阅Box<span class="arithmatex">\(8.1\)</span>获取细节。</p>
<p>设<span class="arithmatex">\(\{d_\pi(s)\}_{s\in\mathcal{S}}\)</span>表示策略<span class="arithmatex">\(\pi\)</span>下马尔可夫过程的稳态分布。即智能体在长时间运行后访问状态<span class="arithmatex">\(s\)</span>的概率为<span class="arithmatex">\(d_\pi(s)\)</span>。根据定义，满足<span class="arithmatex">\(\sum_{s\in\mathcal{S}}d_\pi(s)=1\)</span>。因此，<span class="arithmatex">\((8.3)\)</span>中的目标函数可改写为</p>
<div class="arithmatex">\[J(w)=\sum_{s\in\mathcal{S}}d_\pi(s)(v_\pi(s)-\hat{v}(s,w))^2,\]</div>
<p>这是一个对近似误差进行加权平均的指标。那些被访问概率较高的状态会被赋予更大的权重。</p>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>long-run behavior就是从某一个状态出发，然后我按照策略采取行动，然后不断地去和环境进行交互，然后一直采取这个策略，采取非常多次之后，我就达到了一种平稳的状态，在那个平稳的状态下就得到在每一个状态智能体出现它的概率是多少。</p>
</div>
<p><img alt="" src="../../img/08/14.png" /></p>
<blockquote>
<p>图<span class="arithmatex">\(8.5\)</span>：<span class="arithmatex">\(\varepsilon=0.5\)</span>的<span class="arithmatex">\(\varepsilon\)</span>-贪心策略长期行为。右图中星号表示向量<span class="arithmatex">\(d^\pi\)</span>各分量的理论值。</p>
</blockquote>
<p>值得注意的是，<span class="arithmatex">\(d_\pi(s)\)</span>的值难以直接获取，因为这需要已知状态转移概率矩阵<span class="arithmatex">\(P^\pi\)</span>（参见方框<span class="arithmatex">\(8.1\)</span>）。幸运的是，如后续小节所示，我们无需计算<span class="arithmatex">\(d_\pi(s)\)</span>的具体值即可最小化该目标函数。此外，在引入式<span class="arithmatex">\((8.4)\)</span>和<span class="arithmatex">\((8.5)\)</span>时，我们假设状态数量是有限的。当状态空间连续时，可将求和运算替换为积分运算。</p>
<h3 id="822">8.2.2 优化算法<a class="headerlink" href="#822" title="Permanent link">&para;</a></h3>
<p>为最小化式<span class="arithmatex">\((8.3)\)</span>中的目标函数<span class="arithmatex">\(J(w)\)</span>，可采用梯度下降算法：</p>
<div class="arithmatex">\[w_{k+1}=w_k-\alpha_k\nabla_wJ(w_k),\]</div>
<p>在这里</p>
<div class="arithmatex">\[\begin{aligned}\nabla_wJ(w_k)&amp;=\nabla_w\mathbb{E}[(v_\pi(S)-\hat{v}(S,w_k))^2]\\&amp;=\mathbb{E}[\nabla_w(v_\pi(S)-\hat{v}(S,w_k))^2]\\&amp;=2\mathbb{E}[(v_\pi(S)-\hat{v}(S,w_k))(-\nabla_w\hat{v}(S,w_k))]\\&amp;=-2\mathbb{E}[(v_\pi(S)-\hat{v}(S,w_k))\nabla_w\hat{v}(S,w_k)].\end{aligned}\]</div>
<p>因此，梯度下降算法是</p>
<div class="arithmatex">\[w_{k+1}=w_k+2\alpha_k\mathbb{E}[(v_\pi(S)-\hat{v}(S,w_k))\nabla_w\hat{v}(S,w_k)],\tag{8.11}\]</div>
<p>其中系数<span class="arithmatex">\(2\)</span>可以不失一般性地合并到<span class="arithmatex">\(\alpha_k\)</span>中。式<span class="arithmatex">\((8.11)\)</span>的算法需要计算期望值。根据随机梯度下降法的思想，我们可以用随机梯度替代真实梯度。因此，<span class="arithmatex">\((8.11)\)</span>式可改写为</p>
<div class="arithmatex">\[w_{t+1}=w_t+\alpha_t\left(v_\pi(s_t)-\hat{v}(s_t,w_t)\right)\nabla_w\hat{v}(s_t,w_t),\tag{8.12}\]</div>
<p>其中<span class="arithmatex">\(s_t\)</span>是<span class="arithmatex">\(S\)</span>在时刻<span class="arithmatex">\(t\)</span>的采样值。</p>
<p>值得注意的是，<span class="arithmatex">\((8.12)\)</span>式不可直接实现，因为它需要真实的状态值<span class="arithmatex">\(v_\pi\)</span>——该值未知且必须通过估计获得。我们可以用近似值替代<span class="arithmatex">\(v_\pi(s_t)\)</span>使算法可执行，具体可通过以下两种方法实现。</p>
<ul>
<li>
<p><strong>蒙特卡洛方法</strong>：假设我们有一个回合<span class="arithmatex">\((s_0,r_1,s_1,r_2,\ldots)\)</span>。令<span class="arithmatex">\(g_t\)</span>表示从状态<span class="arithmatex">\(s_t\)</span>开始的折现回报，则<span class="arithmatex">\(g_t\)</span>可作为<span class="arithmatex">\(v_\pi(s_t)\)</span>的估计值。此时式<span class="arithmatex">\((8.12)\)</span>中的算法可改写为</p>
<div class="arithmatex">\[w_{t+1}=w_t+\alpha_t\left(g_t-\hat{v}(s_t,w_t)\right)\nabla_w\hat{v}(s_t,w_t).\]</div>
<p>这是基于函数近似的蒙特卡洛学习算法。</p>
</li>
<li>
<p><strong>时序差分法</strong>：根据TD学习的思想，<span class="arithmatex">\(r_{t+1}+\gamma\hat{v}(s_{t+1},w_t)\)</span>可作为<span class="arithmatex">\(v_\pi(s_t)\)</span>的估计值。此时<span class="arithmatex">\((8.12)\)</span>式中的算法变为</p>
<div class="arithmatex">\[w_{t+1}=w_t+\alpha_t\left[r_{t+1}+\gamma\hat{v}(s_{t+1},w_t)-\hat{v}(s_t,w_t)\right]\nabla_w\hat{v}(s_t,w_t).\tag{8.13}\]</div>
<p>这是基于函数近似的TD学习算法。该算法总结在算法<span class="arithmatex">\(8.1\)</span>中。</p>
</li>
</ul>
<p><img alt="" src="../../img/08/4.png" /></p>
<blockquote>
<p>算法<span class="arithmatex">\(8.1\)</span>: 基于状态值函数近似的TD学习。</p>
</blockquote>
<p>理解式<span class="arithmatex">\((8.13)\)</span>中的TD算法对于研究本章其他算法至关重要。值得注意的是，<span class="arithmatex">\((8.13)\)</span>仅能学习给定策略的状态值。在<span class="arithmatex">\(8.3.1\)</span>和<span class="arithmatex">\(8.3.2\)</span>节中，我们将把它扩展为能够学习行动值的算法。</p>
<h3 id="823">8.2.3 函数近似器的选择<a class="headerlink" href="#823" title="Permanent link">&para;</a></h3>
<p>为应用<span class="arithmatex">\((8.13)\)</span>中的TD算法，需选择合适的<span class="arithmatex">\(\hat{v}(s, w)\)</span>。具体有两种实现方式：其一，采用人工神经网络作为非线性函数近似器，其中网络输入为状态<span class="arithmatex">\(s\)</span>，输出为<span class="arithmatex">\(\hat{v}(s, w)\)</span>，网络参数为<span class="arithmatex">\(w\)</span>；其二，直接采用<strong>线性</strong>函数：</p>
<div class="arithmatex">\[\hat{v}(s,w)=\phi^T(s)w,\]</div>
<p>其中<span class="arithmatex">\(\phi(s) \in \mathbb{R}^m\)</span>表示状态<span class="arithmatex">\(s\)</span>的特征向量。<span class="arithmatex">\(\phi(s)\)</span>与<span class="arithmatex">\(w\)</span>的维度均为<span class="arithmatex">\(m\)</span>，该值通常远小于状态空间的总数。在线性情况下，梯度表达式为</p>
<div class="arithmatex">\[\nabla_w\hat{v}(s,w)=\phi(s),\]</div>
<p>将其代入式<span class="arithmatex">\((8.13)\)</span>可得</p>
<div class="arithmatex">\[w_{t+1}=w_t+\alpha_t\left[r_{t+1}+\gamma\phi^T(s_{t+1})w_t-\phi^T(s_t)w_t\right]\phi(s_t).\tag{8.14}\]</div>
<p>这是采用线性函数近化的TD学习算法，简称为TD-Linear。</p>
<p>线性情况在理论上比非线性情况更易理解，但其近似能力有限。对于复杂任务，选择合适的特征向量也非易事。相比之下，人工神经网络作为黑箱非线性近似器，能够更好地近似目标值，且更易于使用。</p>
<p>然而，研究线性情形仍具重要意义。深入理解线性情形有助于读者更好地掌握函数近似方法的核心思想。此外，本书讨论的简单网格世界任务中，线性情形已足以解决问题。更重要的是，从表格化方法可视为特殊线性情形这一视角来看，线性方法仍具有强大的能力。关于表格化方式为什么是一种特殊的TD-Linear可参阅Box 8.2。</p>
<h3 id="824">8.2.4 例子<a class="headerlink" href="#824" title="Permanent link">&para;</a></h3>
<p>接下来我们通过示例展示如何利用<span class="arithmatex">\((8.14)\)</span>中的TD-Linear算法估计给定策略的状态值，同时说明特征向量的选取方法。</p>
<p><img alt="" src="../../img/08/5.png" /></p>
<blockquote>
<p>图<span class="arithmatex">\(8.6\)</span>:<span class="arithmatex">\((a)\)</span>待评估策略。<span class="arithmatex">\((b)\)</span>真实状态值以表格形式呈现。<span class="arithmatex">\((c)\)</span>真实状态值以三维曲面形式呈现。</p>
</blockquote>
<p>网格世界示例如图<span class="arithmatex">\(8.6\)</span>所示。给定策略在每个状态下以<span class="arithmatex">\(0.2\)</span>的概率采取任意动作。我们的目标是估计该策略下的状态值。该系统共包含<span class="arithmatex">\(25\)</span>个状态值。真实状态值如图<span class="arithmatex">\(8.6(b)\)</span>所示，其三维曲面可视化结果展示在图<span class="arithmatex">\(8.6(c)\)</span>中。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>总共有25个状态值，如果用表格的方式，那么需要存储25个状态值。</p>
</div>
<p>接下来我们证明，可以用少于<span class="arithmatex">\(25\)</span>个参数来近似这些状态值。仿真设置如下：通过给定策略生成<span class="arithmatex">\(500\)</span>个回合，每个回合包含<span class="arithmatex">\(500\)</span>个步长，每个回合出发的状态-行动对是随机选择的，并且遵循均匀分布。此外，在每次仿真试验中，参数向量<span class="arithmatex">\(w\)</span>被随机初始化，其每个元素均从均值为<span class="arithmatex">\(0\)</span>、标准差为<span class="arithmatex">\(1\)</span>的标准正态分布中抽取。我们设定<span class="arithmatex">\(r_{\text{forbidden}} = r_{\text{boundary}} = -1\)</span>，<span class="arithmatex">\(r_{\text{target}} =1\)</span>，以及<span class="arithmatex">\(\gamma =0.9\)</span>。</p>
<p>为实现TD-Linear算法，首先需要选择特征向量<span class="arithmatex">\(\phi(s)\)</span>。具体实现方式如下所示。</p>
<ul>
<li>
<p>第一种特征向量基于多项式构建。在网格世界示例中，状态<span class="arithmatex">\(s\)</span>对应二维坐标位置，其中<span class="arithmatex">\(x\)</span>和<span class="arithmatex">\(y\)</span>分别表示<span class="arithmatex">\(s\)</span>的列索引与行索引。为避免数值问题，我们将<span class="arithmatex">\(x\)</span>和<span class="arithmatex">\(y\)</span>归一化至区间<span class="arithmatex">\([-1, +1]\)</span>内。在不引起歧义的前提下，归一化后的值仍用<span class="arithmatex">\(x\)</span>和<span class="arithmatex">\(y\)</span>表示。此时，最简单的特征向量可表示为</p>
<p><span class="arithmatex">\(\phi(s)=\begin{bmatrix}x\\y\end{bmatrix}\in\mathbb{R}^2.\)</span></p>
<p>在此情况下，我们有</p>
<div class="arithmatex">\[\hat{v}(s,w)=\phi^T(s)w=[x,y]\begin{bmatrix}w_1\\w_2\end{bmatrix}=w_1x+w_2y.\]</div>
<p>当给定<span class="arithmatex">\(w\)</span>时，<span class="arithmatex">\(\hat{v}(s, w) = w_1x + w_2y\)</span>表示一个通过原点的二维平面。由于状态值曲面可能不经过原点，我们需要为该二维平面引入偏置项以更好地逼近状态值。为此，我们考虑以下三维特征向量：</p>
<div class="arithmatex">\[\phi(s)=\begin{bmatrix}1\\x\\y\end{bmatrix}\in\mathbb{R}^3.\tag{8.15}\]</div>
<p>在此情况下，近似状态值为</p>
<div class="arithmatex">\[\hat{v}(s,w)=\phi^T(s)w=[1,x,y]\begin{bmatrix}w_1\\w_2\\w_3\end{bmatrix}=w_1+w_2x+w_3y.\]</div>
<p>当给定<span class="arithmatex">\(w\)</span>时，<span class="arithmatex">\(\hat{v}(s, w)\)</span>对应一个可能不经过原点的平面。值得注意的是<span class="arithmatex">\(\varphi(s)\)</span>也可以定义为<span class="arithmatex">\(\varphi(s) = [x, y,1]^T\)</span>，其中元素的排列顺序无关紧要。</p>
<p>采用式<span class="arithmatex">\((8.15)\)</span>中特征向量所得的估计结果如图<span class="arithmatex">\(8.7(a)\)</span>。可以看出，估计的状态值形成一个二维平面。尽管随着使用更多训练回合估计误差会收敛，但由于二维平面的近似能力有限，该误差无法降至零。</p>
<p>为提升近似能力，可通过增加特征向量的维度实现。为此，考虑</p>
<div class="arithmatex">\[\phi(s)=[1,x,y,x^2,y^2,xy]^T\in\mathbb{R}^6.\tag{8.16}\]</div>
<p>在这种情况下，<span class="arithmatex">\(\hat{v}(s, w) = \varphi^T(s)w = w_1 + w_2x + w_3y + w_4x^2 + w_5y^2 + w_6xy\)</span>，对应一个二次三维曲面。我们可以进一步增加特征向量的维度：</p>
<div class="arithmatex">\[\phi(s)=[1,x,y,x^2,y^2,xy,x^3,y^3,x^2y,xy^2]^T\in\mathbb{R}^{10}.\tag{8.17}\]</div>
<p>使用式<span class="arithmatex">\((8.16)\)</span>和<span class="arithmatex">\((8.17)\)</span>中特征向量得到的估计结果如图<span class="arithmatex">\(8.7(b)-(c)\)</span>所示。可以看出，特征向量越长，状态值的近似精度越高。但在所有三种情况下，估计误差均无法收敛至零，这是因为这些线性近似器仍存在表达能力局限。</p>
</li>
</ul>
<p><img alt="" src="../../img/08/6.png" /></p>
<blockquote>
<p>图<span class="arithmatex">\(8.7\)</span>：采用多项式特征<span class="arithmatex">\((8.15)\)</span>,<span class="arithmatex">\((8.16)\)</span>和<span class="arithmatex">\((8.17)\)</span>得到的TD-Linear估计结果。</p>
</blockquote>
<ul>
<li>
<p>除了多项式特征向量外，还存在多种其他类型的特征表示方法，例如傅里叶基(Fourier basis)和片编码(Tile coding)[3,第9章]。首先，需确定变量<span class="arithmatex">\(x\)</span>与<span class="arithmatex">\(y\)</span>的
各状态量被归一化至区间[0,1]。所得特征向量为</p>
<div class="arithmatex">\[\left.\phi(s)=\left[\begin{array}{c}\vdots\\\cos\left(\pi(c_1x+c_2y)\right)\\\vdots\end{array}\right.\right]\in\mathbb{R}^{(q+1)^2},\tag{8.18}\]</div>
<p>其中<span class="arithmatex">\(\pi\)</span>表示圆周率，其值为<span class="arithmatex">\(3.1415...\)</span>，而非策略。此处<span class="arithmatex">\(c_1\)</span>或<span class="arithmatex">\(c_2\)</span>可设置为集合<span class="arithmatex">\(\{0,1, ..., q\}\)</span>中的任意整数，其中<span class="arithmatex">\(q\)</span>为用户指定整数。因此，二元组<span class="arithmatex">\((c_1, c_2)\)</span>共有<span class="arithmatex">\((q +1)^2\)</span>种可能的取值组合，故特征映射<span class="arithmatex">\(\phi(s)\)</span>的维度为<span class="arithmatex">\((q +1)^2\)</span>。例如当<span class="arithmatex">\(q=1\)</span>时，特征向量可表示为</p>
<div class="arithmatex">\[\left.\phi(s)=\left[\begin{array}{c}\cos\left(\pi(0x+0y)\right)\\\cos\left(\pi(0x+1y)\right)\\\cos\left(\pi(1x+0y)\right)\\\cos\left(\pi(1x+1y)\right)\end{array}\right.\right]=\begin{bmatrix}1\\\cos(\pi y)\\\cos(\pi x)\\\cos(\pi(x+y))\end{bmatrix}\in\mathbb{R}^4.\]</div>
<p>采用<span class="arithmatex">\(q =1,2,3\)</span>的傅里叶特征进行估计的结果如图<span class="arithmatex">\(8.8\)</span>所示。三种情况下特征向量的维度分别为<span class="arithmatex">\(4,9,16\)</span>。可以看出，特征向量维度越高，状态值的近似精度越高。</p>
</li>
</ul>
<p><img alt="" src="../../img/08/7.png" /></p>
<blockquote>
<p>图<span class="arithmatex">\(8.8\)</span>：采用式<span class="arithmatex">\((8.18)\)</span>中傅里叶特征得到的TD-Linear估计结果。</p>
</blockquote>
<h3 id="825">8.2.5 理论分析<a class="headerlink" href="#825" title="Permanent link">&para;</a></h3>
<p>至此，我们已经完整阐述了函数近似下的TD学习理论框架。该框架的起点是公式<span class="arithmatex">\((8.3)\)</span>中的目标函数。为优化这一目标，我们在<span class="arithmatex">\((8.12)\)</span>中引入了随机算法。随后，将该算法中未知的真实值函数替换为近似值，从而得到<span class="arithmatex">\((8.13)\)</span>中的TD算法。虽然这个叙述有助于理解值函数近似的基本思想，但从数学角度并不严谨。例如，<span class="arithmatex">\((8.13)\)</span>中的算法实际上并未最小化<span class="arithmatex">\((8.3)\)</span>中的目标函数。</p>
<p>接下来，我们对式<span class="arithmatex">\((8.13)\)</span>中的TD算法进行理论分析，以揭示该算法高效运作的机理及其解决的数学问题。由于非线性近似器难以分析，本节仅讨论线性情形。鉴于本部分数学推导较为密集，建议读者根据兴趣选择性阅读。</p>
<h4 id="_2">收敛性分析<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h4>
<p>为研究式 (8.13)的收敛性，我们首先考察以下确定性算法:</p>
<div class="arithmatex">\[w_{t+1}=w_t+\alpha_t\mathbb{E}\left[\left(r_{t+1}+\gamma\phi^T(s_{t+1})w_t-\phi^T(s_t)w_t\right)\phi(s_t)\right],\tag{8.19}\]</div>
<p>其中期望值是关于随机变量<span class="arithmatex">\(s_t\)</span>,<span class="arithmatex">\(s_{t+1}\)</span>.<span class="arithmatex">\(r_{t+1}\)</span>计算的。假设<span class="arithmatex">\(s_t\)</span>的分布为平稳分布<span class="arithmatex">\(d^\pi\)</span>。式<span class="arithmatex">\((8.19)\)</span>中的算法是确定性的，因为在计算期望后，随机变量<span class="arithmatex">\(s_t\)</span>,<span class="arithmatex">\(s_{t+1}\)</span>.<span class="arithmatex">\(r_{t+1}\)</span>均被消除。</p>
<p>我们为何考虑这一确定性算法？首先，该确定性算法的收敛性分析更为简便(尽管并非平凡)；其次且更重要的是，其收敛性可推导出随机TD算法<span class="arithmatex">\((8.13)\)</span>的收敛性。这是因为<span class="arithmatex">\((8.13)\)</span>可视为<span class="arithmatex">\((8.19)\)</span>的随机梯度下降<span class="arithmatex">\((SGD)\)</span>实现。因此，我们仅需研究确定性算法的收敛特性。</p>
<p>虽然式<span class="arithmatex">\((8.19)\)</span>的表达式初看可能较为复杂，但可大幅简化。为此，定义</p>
<div class="arithmatex">\[\Phi=\begin{bmatrix}\vdots\\\phi^T(s)\\\vdots\end{bmatrix}\in\mathbb{R}^{n\times m},\quad D=\begin{bmatrix}\ddots\\&amp;d_\pi(s)\\&amp;&amp;\ddots\end{bmatrix}\in\mathbb{R}^{n\times n},\tag{8.20}\]</div>
<p>其中<span class="arithmatex">\(\Phi\)</span>为包含所有特征向量的矩阵，<span class="arithmatex">\(D\)</span>是以平稳分布为对角元素的对角矩阵。这两个矩阵将频繁使用。</p>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p><strong>引理8.1</strong>. 式<span class="arithmatex">\((8.19)\)</span>中的期望可改写为</p>
<div class="arithmatex">\[\mathrm{E}\left[\left(r_{t+1}+\gamma\phi^{T}(s_{t+1})w_{t}-\phi^{T}(s_{t})w_{t}\right)\phi(s_{t})\right]=b-Aw_{t},\]</div>
<p>在这里</p>
<div class="arithmatex">\[\begin{aligned}&amp;A\doteq\Phi^{T}D(I-\gamma P_{\pi})\Phi\in\mathbb{R}^{m\times m},\\&amp;b\doteq\Phi^{T}Dr_{\pi}\in\mathbb{R}^{m}.\end{aligned}\tag{8.21}\]</div>
<p>此处，<span class="arithmatex">\(P_\pi\)</span>和 <span class="arithmatex">\(r_\pi\)</span>是贝尔曼方程<span class="arithmatex">\(v_\pi = r_\pi + \gamma P_\pi v_\pi\)</span>中的两项，<span class="arithmatex">\(I\)</span>为相应维度的单位矩阵。</p>
</div>
<p>证明过程见Box 8.3。根据引理<span class="arithmatex">\(8.1\)</span>中的表达式，确定性算法<span class="arithmatex">\((8.19)\)</span>可改写为</p>
<div class="arithmatex">\[w_{t+1}=w_t+\alpha_t(b-Aw_t),\tag{8.22}\]</div>
<p>这是一个简单的确定性过程，其收敛性分析如下。</p>
<p>首先，<span class="arithmatex">\(w_t\)</span>的收敛值是多少？假设当<span class="arithmatex">\(t\rightarrow \infty\)</span>时，<span class="arithmatex">\(w_t\)</span>收敛至常数值<span class="arithmatex">\(w^∗\)</span>，则由式<span class="arithmatex">\((8.22)\)</span>可得<span class="arithmatex">\(w^∗ = w^∗ + \alpha_\infty(b − Aw^*)\)</span>，这意味着<span class="arithmatex">\(b − Aw^* =0\)</span>，因此</p>
<div class="arithmatex">\[w^*=A^{-1}b.\]</div>
<p>关于该收敛值的几点说明如下。</p>
<ul>
<li>
<p>矩阵<span class="arithmatex">\(A\)</span>是否可逆？答案是肯定的。事实上，<span class="arithmatex">\(A\)</span>不仅可逆，还是正定矩阵。也就是说，对于任意适当维度的非零向量 <span class="arithmatex">\(\mathbf{x}\)</span>，均有<span class="arithmatex">\(\mathbf{x}^T A \mathbf{x} &gt;0\)</span>。证明过程见Box 8.4。</p>
</li>
<li>
<p>如何解释<span class="arithmatex">\(w^* = A^{-1}b\)</span>的含义？它实际上是<strong>最小化投影贝尔曼误差</strong>的最优解。具体细节将在第8.2.5节中阐述。</p>
</li>
<li>
<p>表格化方法是一种特殊情况。一个有趣的结果是，当权重向量<span class="arithmatex">\(\mathbf{w}\)</span>的维度等于状态空间大小<span class="arithmatex">\(n = |\mathcal{S}|\)</span>且特征函数<span class="arithmatex">\(\phi(s) = [0, \ldots,1, \ldots,0]^T\)</span>(其中对应状态<span class="arithmatex">\(s\)</span>的元素为<span class="arithmatex">\(1\)</span>)时，我们得到</p>
</li>
</ul>
<div class="arithmatex">\[w^*=A^{-1}b=v_\pi.\tag{8.23}\]</div>
<p>该方程表明待学习的参数向量实际上是真实状态值。这一结论与表格型TD算法是TD-Linear算法特例的事实相符(如Box 8.2所述)。式<span class="arithmatex">\((8.23)\)</span>的证明如下：此时可验证<span class="arithmatex">\(\Phi = I\)</span>，因此<span class="arithmatex">\(A = \Phi^\text{T}D(I - \gamma P^\pi)\Phi = D(I - \gamma P^\pi)\)</span>且<span class="arithmatex">\(b = \Phi^\text{T}Dr^\pi = Dr^\pi\)</span>。故而有<span class="arithmatex">\(w^* = A^{-1}b = (I - \gamma P^\pi)^{-1}D^{-1}Dr^\pi = (I - \gamma P^\pi)^{-1}r^\pi = v^\pi\)</span>。</p>
<p>其次，我们证明当<span class="arithmatex">\(t \to \infty\)</span>时，<span class="arithmatex">\((8.22)\)</span>式中的<span class="arithmatex">\(w_t\)</span>收敛于<span class="arithmatex">\(w^* = A^{-1}b\)</span>。由于<span class="arithmatex">\((8.22)\)</span>式是一个简单的确定性过程，可通过多种方法证明。下面给出两种证明方式。</p>
<ul>
<li>
<p>证明方法1: 定义收敛误差为<span class="arithmatex">\(\delta_t = w_t - w^*\)</span>。只需证明<span class="arithmatex">\(\delta_t\)</span>收敛于零即可。为此，将<span class="arithmatex">\(w_t = \delta_t + w^*\)</span></p>
<div class="arithmatex">\[\delta_{t+1}=\delta_t-\alpha_tA\delta_t=(I-\alpha_tA)\delta_t.\]</div>
<p>由此可得</p>
<div class="arithmatex">\[\delta_{t+1}=(I-\alpha_tA)\cdots(I-\alpha_0A)\delta_0.\]</div>
<p>考虑所有时刻 <span class="arithmatex">\(t\)</span>下 <span class="arithmatex">\(\alpha_t = \alpha\)</span>的简单情形，此时可得</p>
<div class="arithmatex">\[\|\delta_{t+1}\|_2\leq\|I-\alpha A\|_2^{t+1}\|\delta_0\|_2.\]</div>
<p>当<span class="arithmatex">\(\alpha &gt;0\)</span>充分小时，有<span class="arithmatex">\(\|I - \alpha A\|_2 &lt;1\)</span>，因此当<span class="arithmatex">\(t \to \infty\)</span>时<span class="arithmatex">\(\delta_t \to0\)</span>。该不等式成立的原因是<span class="arithmatex">\(A\)</span>正定，故对任意<span class="arithmatex">\(x\)</span>均有<span class="arithmatex">\(x^T(I - \alpha A)x &lt;1\)</span>。</p>
</li>
<li>
<p>证明方法2: 考虑函数<span class="arithmatex">\(g(w) = b - Aw\)</span>。由于<span class="arithmatex">\(w^*\)</span>是方程<span class="arithmatex">\(g(w) =0\)</span>的根，该问题本质上是一个求根问题。式<span class="arithmatex">\((8.22)\)</span>中的算法实际上是一种RM算法。虽然原始 RM算法是为随机过程设计的，但它同样适用于确定性情形。RM算法的收敛性可以解释迭代式<span class="arithmatex">\(w_{t+1} = w_t + \alpha_t(b - Aw_t)\)</span>的收敛行为：当满足<span class="arithmatex">\(\sum_t \alpha_t = \infty\)</span>且<span class="arithmatex">\(\sum_t \alpha_t^2 &lt; \infty\)</span>时，<span class="arithmatex">\(w_t\)</span>将收敛至<span class="arithmatex">\(w^*\)</span>。</p>
</li>
</ul>
<h4 id="td">TD学习最小化投影贝尔曼误差<a class="headerlink" href="#td" title="Permanent link">&para;</a></h4>
<p>虽然我们已经证明TD-Linear算法收敛于<span class="arithmatex">\(w^* = A^{-1}b\)</span>，但接下来我们将证明<span class="arithmatex">\(w^*\)</span>是最小化投影贝尔曼误差的最优解。为此，我们首先回顾三个目标函数。</p>
<ul>
<li>
<p>第一个目标函数是</p>
<div class="arithmatex">\[J_E(w)=\mathbb{E}[(v_\pi(S)-\hat{v}(S,w))^2],\]</div>
<p>该定义已在(8.3)节中给出。根据期望的定义，<span class="arithmatex">\(J_E(\mathbf{w})\)</span>可重新表示为矩阵-向量形式：</p>
<div class="arithmatex">\[J_E(w)=\|\hat{v}(w)-v_\pi\|_D^2,\]</div>
<p>其中 <span class="arithmatex">\(v_\pi\)</span>为真实状态值向量，<span class="arithmatex">\(\hat{v}(w)\)</span>为其近似值。此处 <span class="arithmatex">\(\|\cdot\|_D\)</span>为加权范数：<span class="arithmatex">\(\|x\|_D^2 = x^\top D x = \|D^{1/2}x\|_2^2\)</span>，其中 <span class="arithmatex">\(D\)</span>由式 (8.20)给出。</p>
<p>这是我们在讨论函数逼近时能设想的最简单目标函数。然而，它依赖于真实状态(该状态未知)。为获得可实现的算法，我们必须考虑其他目标函数，例如贝尔曼误差和投影贝尔曼误差[50–54]。</p>
</li>
<li>
<p>第二个目标函数是贝尔曼误差(Bellman error)。特别地，由于<span class="arithmatex">\(v_\pi\)</span>满足贝尔曼方程<span class="arithmatex">\(v_\pi = r_\pi + \gamma P_\pi v_\pi\)</span>，可以预期估计值<span class="arithmatex">\(\hat{v}(w)\)</span>也应尽可能满足该方程。因此，贝尔曼误差为</p>
<div class="arithmatex">\[J_{BE}(w)=\|\hat{v}(w)-(r_\pi+\gamma P_\pi\hat{v}(w))\|_D^2\doteq\|\hat{v}(w)-T_\pi(\hat{v}(w))\|_D^2.\tag{8.30}\]</div>
<p>此处，<span class="arithmatex">\(T_\pi(\cdot)\)</span>为贝尔曼算子。特别地，对于任意向量 <span class="arithmatex">\(\mathbf{x} \in \mathbb{R}^n\)</span>，贝尔曼算子定义为</p>
<div class="arithmatex">\[T_\pi(x)\doteq r_\pi+\gamma P_\pi x.\]</div>
<p>最小化贝尔曼误差是一个标准的最小二乘问题。此处省略求解过程的细节。</p>
</li>
<li>
<p>第三，值得注意的是，<span class="arithmatex">\((8.30)\)</span>中的 <span class="arithmatex">\(J_{BE}(w)\)</span>可能无法被最小化至零，这是由于近似器的有限近似能力所致。相比之下，能够被最小化至零的目标函数是投影贝尔曼误差(projected bellman error)：</p>
<div class="arithmatex">\[J_{PBE}(w)=\|\hat{v}(w)-MT_\pi(\hat{v}(w))\|_D^2,\]</div>
<p>其中<span class="arithmatex">\(M \in \mathbb{R}^{n \times n}\)</span>为正交投影矩阵，其几何意义是将任意向量投影至所有近似解构成的空间。</p>
</li>
</ul>
<p>事实上，<span class="arithmatex">\((8.13)\)</span>中的TD学习算法旨在最小化投影贝尔曼误差<span class="arithmatex">\(J_{PBE}\)</span>而非<span class="arithmatex">\(J_E\)</span>或<span class="arithmatex">\(J_{BE}\)</span>。原因如下：为简化分析，考虑线性情况<span class="arithmatex">\(\hat{v}(w) = \Phi w\)</span>，其中<span class="arithmatex">\(\Phi\)</span>由<span class="arithmatex">\((8.20)\)</span>式定义。<span class="arithmatex">\(\Phi\)</span>的值域空间是所有可能的线性近似构成的集合。此时，</p>
<div class="arithmatex">\[M=\Phi(\Phi^TD\Phi)^{-1}\Phi^TD\in\mathbb{R}^{n\times n}\]</div>
<p>是投影矩阵，可将任意向量几何投影到值域空间<span class="arithmatex">\(\Phi\)</span>上。由于<span class="arithmatex">\(\hat{v}(w)\)</span>位于 <span class="arithmatex">\(\Phi\)</span>的值域空间内，总能找到使<span class="arithmatex">\(J_{PBE}(w)\)</span>最小化至零的<span class="arithmatex">\(w\)</span>值。可以证明，使<span class="arithmatex">\(J_{PBE}(w)\)</span>最小化的解为<span class="arithmatex">\(w^* = A^{-1}b\)</span>。即</p>
<div class="arithmatex">\[w^*=A^{-1}b=\arg\min_wJ_{PBE}(w),\]</div>
<p>证明在Box 8.5中给出</p>
<p>由于TD算法的目标是最小化<span class="arithmatex">\(J_{PBE}\)</span>而非<span class="arithmatex">\(J_E\)</span>，自然会产生一个问题：估计值<span class="arithmatex">\(\hat{v}(w)\)</span>与真实状态值<span class="arithmatex">\(v_\pi\)</span>的接近程度如何？在线性情况下，最小化投影贝尔曼误差的估计值为<span class="arithmatex">\(\hat{v}(w^*) = \Phi w^*\)</span>。该估计值与真实状态值<span class="arithmatex">\(v_\pi\)</span>的偏差满足</p>
<div class="arithmatex">\[\|\hat{v}(w^*)-v_\pi\|_D=\|\Phi w^*-v_\pi\|_D\leq\frac{1}{1-\gamma}\min_w\|\hat{v}(w)-v_\pi\|_D=\frac{1}{1-\gamma}\min_w\sqrt{J_E(w)}.\tag{8.32}\]</div>
<p>该不等式的证明见Box 8.6。不等式<span class="arithmatex">\((8.32)\)</span>表明，<span class="arithmatex">\(\Phi w^*\)</span>与<span class="arithmatex">\(v_\pi\)</span>之间的差异上界由<span class="arithmatex">\(J_E(w)\)</span>的最小值决定。然而该界限较为宽松，尤其当<span class="arithmatex">\(\gamma\)</span>接近<span class="arithmatex">\(1\)</span>时。因此该结论主要具有理论价值。</p>
<h4 id="td_1">最小二乘TD<a class="headerlink" href="#td_1" title="Permanent link">&para;</a></h4>
<p>接下来我们介绍一种称为最小二乘时序差分(LSTD)的算法[57]。与线性时序差分(TD-Linear)算法类似，LSTD的目标是最小化投影贝尔曼误差。但该算法相较于TD-Linear具有若干优势。</p>
<p>回顾最小化投影贝尔曼误差的最优参数为<span class="arithmatex">\(w^* = A^{-1}b\)</span>，其中<span class="arithmatex">\(A = \Phi^TD(I - \gamma P^\pi)\Phi\)</span>且<span class="arithmatex">\(b = \Phi^TDr^\pi\)</span>。实际上，由式<span class="arithmatex">\((8.27)\)</span>可知，<span class="arithmatex">\(A\)</span>和<span class="arithmatex">\(b\)</span>亦可表示为</p>
<div class="arithmatex">\[\begin{aligned}&amp;A=\mathbb{E}\left[\phi(s_t)\left(\phi(s_t)-\gamma\phi(s_{t+1})\right)^T\right],\\&amp;b=\mathbb{E}\left[r_{t+1}\phi(s_{t})\right].\end{aligned}\]</div>
<p>上述两个方程表明，<span class="arithmatex">\(A\)</span>和 <span class="arithmatex">\(b\)</span>分别是 <span class="arithmatex">\(s_t\)</span>、<span class="arithmatex">\(s_{t+1}\)</span>、<span class="arithmatex">\(r_{t+1}\)</span>的期望值。LSTD算法的核心思想很简单：若能通过随机采样直接获得<span class="arithmatex">\(A\)</span>和<span class="arithmatex">\(b\)</span>的估计量<span class="arithmatex">\(\hat{A}\)</span>与<span class="arithmatex">\(\hat{b}\)</span>，则最优参数可直接估计为<span class="arithmatex">\(w^* \approx \hat{A}^{-1}\hat{b}\)</span>。</p>
<p>特别地，假设<span class="arithmatex">\((s_0, r_1, s_1, \ldots, s_t, r_{t+1}, s_{t+1}, \ldots)\)</span>是通过遵循给定策略<span class="arithmatex">\(\pi\)</span>所获得的轨迹。设<span class="arithmatex">\(\hat{A}_t\)</span>和 <span class="arithmatex">\(\hat{b}_t\)</span>分别为时刻<span class="arithmatex">\(t\)</span>时<span class="arithmatex">\(A\)</span>和<span class="arithmatex">\(b\)</span>的估计值，其计算方式为样本均值：</p>
<div class="arithmatex">\[\begin{aligned}&amp;\mathrm{A}=\sum_{k=0}^{t-1}\phi(s_k)\left(\phi(s_k)-\gamma\phi(s_{k+1})\right)^T,\\&amp;\hat{b}_{t}=\sum_{k=0}^{t-1}r_{k+1}\phi(s_{k}).\end{aligned}\tag{8.34}\]</div>
<p>则估计参数为</p>
<div class="arithmatex">\[w_t=\hat{A}_t^{-1}\hat{b}_t.\]</div>
<p>读者可能会疑惑<span class="arithmatex">\((8.34)\)</span>式右侧是否遗漏了<span class="arithmatex">\(1/t\)</span>的系数。实际上，该系数被有意省略以简化表达式，因为省略后<span class="arithmatex">\(w_t\)</span>的值保持不变。由于<span class="arithmatex">\(\hat{A}_t\)</span>在小样本情况下可能不可逆，通常需要对其施加微小偏置<span class="arithmatex">\(\sigma I\)</span>(其中<span class="arithmatex">\(I\)</span>为单位矩阵，<span class="arithmatex">\(\sigma\)</span>为微小正数)。</p>
<p>LSTD算法的优势在于，相较于TD方法，它能更高效地利用经验样本且收敛速度更快。这是因为该算法是专门基于最优解表达式知识设计的——对问题的理解越深入，算法设计就越精良。</p>
<p>LSTD算法的缺点如下。首先，它仅能估计状态值；相比之下，如后文所示，TD算法可扩展至行动值估计。此外，TD算法允许使用非线性近似器，而LSTD则不具备该特性——这是因为该算法是专门基于<span class="arithmatex">\(w^*\)</span>的表达式设计的。其次，LSTD的计算成本高于TD算法：LSTD在每次更新步骤中需处理<span class="arithmatex">\(m \times m\)</span>矩阵，而TD仅更新<span class="arithmatex">\(m\)</span>维向量。更重要的是，LSTD每一步都需要计算<span class="arithmatex">\(\hat{A}_t\)</span>的逆矩阵，其计算复杂度为<span class="arithmatex">\(O(m^3)\)</span>。解决该问题的通用方法是直接更新<span class="arithmatex">\(\hat{A}_t\)</span>的逆矩阵而非<span class="arithmatex">\(\hat{A}_t\)</span>本身，具体而言，<span class="arithmatex">\(\hat{A}_{t+1}\)</span>可通过如下递归方式计算：</p>
<div class="arithmatex">\[\begin{aligned}\hat{A}_{t+1}&amp;=\sum_{k=0}^t\phi(s_k)\left(\phi(s_k)-\gamma\phi(s_{k+1})\right)^T\\&amp;=\sum_{k=0}^{t-1}\phi(s_{k})\left(\phi(s_{k})-\gamma\phi(s_{k+1})\right)^{T}+\phi(s_{t})\left(\phi(s_{t})-\gamma\phi(s_{t+1})\right)^{T}\\&amp;=\hat{A}_t+\phi(s_t)\left(\phi(s_t)-\gamma\phi(s_{t+1})\right)^T.\end{aligned}\]</div>
<p>上述表达式将 <span class="arithmatex">\(\hat{A}_{t+1}\)</span>分解为两个矩阵之和，其逆矩阵可按文献[58]方法计算为</p>
<div class="arithmatex">\[\begin{aligned}\hat{A}_{t+1}^{-1}&amp;=\left(\hat{A}_{t}+\phi(s_{t})\left(\phi(s_{t})-\gamma\phi(s_{t+1})\right)^{T}\right)^{-1}\\&amp;=\hat{A}_{t}^{-1}+\frac{\hat{A}_{t}^{-1}\phi(s_{t})\left(\phi(s_{t})-\gamma\phi(s_{t+1})\right)^{T}\hat{A}_{t}^{-1}}{1+\left(\phi(s_{t})-\gamma\phi(s_{t+1})\right)^{T}\hat{A}_{t}^{-1}\phi(s_{t})}.\end{aligned}\]</div>
<p>因此，我们可以直接存储并更新<span class="arithmatex">\(\hat{A}^{-1}_t\)</span>以避免计算矩阵逆。该递归算法无需设置步长，但需要给定<span class="arithmatex">\(\hat{A}^{-1}_0\)</span>的初始值。此类递归算法的初始值通常选为<span class="arithmatex">\(\hat{A}^{-1}_0 = \sigma I\)</span>，其中<span class="arithmatex">\(\sigma\)</span>为正数。关于递归最小二乘法的详细教程可参阅文献[59]。</p>





                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            回到页面顶部
          </button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="页脚" >
        
          
          <a href="../8-1/" class="md-footer__link md-footer__link--prev" aria-label="上一页: 8.1-价值表示:从表格到函数" rel="prev">
            <div class="md-footer__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                上一页
              </span>
              <div class="md-ellipsis">
                8.1-价值表示:从表格到函数
              </div>
            </div>
          </a>
        
        
          
          <a href="../8-3/" class="md-footer__link md-footer__link--next" aria-label="下一页: 8.3-基于值函数的时序差分算法:行动值估计" rel="next">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                下一页
              </span>
              <div class="md-ellipsis">
                8.3-基于值函数的时序差分算法:行动值估计
              </div>
            </div>
            <div class="md-footer__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/wgyhhhh/" target="_blank" rel="noopener" title="GitHub" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://space.bilibili.com/281217178" target="_blank" rel="noopener" title="哔哩哔哩" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M488.6 104.1c16.7 18.1 24.4 39.7 23.3 65.7v202.4c-.4 26.4-9.2 48.1-26.5 65.1-17.2 17-39.1 25.9-65.5 26.7H92.02c-26.45-.8-48.21-9.8-65.28-27.2C9.682 419.4.767 396.5 0 368.2V169.8c.767-26 9.682-47.6 26.74-65.7C43.81 87.75 65.57 78.77 92.02 78h29.38L96.05 52.19c-5.75-5.73-8.63-13-8.63-21.79 0-8.8 2.88-16.06 8.63-21.797C101.8 2.868 109.1 0 117.9 0s16.1 2.868 21.9 8.603L213.1 78h88l74.5-69.397C381.7 2.868 389.2 0 398 0c8.8 0 16.1 2.868 21.9 8.603 5.7 5.737 8.6 12.997 8.6 21.797 0 8.79-2.9 16.06-8.6 21.79L394.6 78h29.3c26.4.77 48 9.75 64.7 26.1zm-38.8 69.7c-.4-9.6-3.7-17.4-10.7-23.5-5.2-6.1-14-9.4-22.7-9.8H96.05c-9.59.4-17.45 3.7-23.58 9.8-6.14 6.1-9.4 13.9-9.78 23.5v194.4c0 9.2 3.26 17 9.78 23.5s14.38 9.8 23.58 9.8H416.4c9.2 0 17-3.3 23.3-9.8 6.3-6.5 9.7-14.3 10.1-23.5V173.8zm-264.3 42.7c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.2 6.3-14 9.5-23.6 9.5-9.6 0-17.5-3.2-23.6-9.5-6.1-6.3-9.4-14-9.8-23.2v-33.3c.4-9.1 3.8-16.9 10.1-23.2 6.3-6.3 13.2-9.6 23.3-10 9.2.4 17 3.7 23.3 10zm191.5 0c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.1 6.3-14 9.5-23.6 9.5-9.6 0-17.4-3.2-23.6-9.5-7-6.3-9.4-14-9.7-23.2v-33.3c.3-9.1 3.7-16.9 10-23.2 6.3-6.3 14.1-9.6 23.3-10 9.2.4 17 3.7 23.3 10z"/></svg>
    </a>
  
    
    
    
    
    <a href="mailto:wgyhhh001@gmail.com" target="_blank" rel="noopener" title="联系作者" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.7l167.6-182.9c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-consent" data-md-component="consent" id="__consent" hidden>
        <div class="md-consent__overlay"></div>
        <aside class="md-consent__inner">
          <form class="md-consent__form md-grid md-typeset" name="consent">
            


  
    
  




<h4>Cookie 设置</h4>
<p>我们使用 cookies 来识别您的重复访问和偏好，以及衡量我们文档的有效性和用户是否找 到他们正在搜索的内容。<br/> 在您的同意下，您将帮助我们改进我们的文档。<br/> （您稍后仍可以在网页左下角重新修改 cookies 设置）</p>
<input class="md-toggle" type="checkbox" id="__settings" >
<div class="md-consent__settings">
  <ul class="task-list">
    
      
      
        
        
      
      <li class="task-list-item">
        <label class="task-list-control">
          <input type="checkbox" name="github" checked>
          <span class="task-list-indicator"></span>
          GitHub
        </label>
      </li>
    
  </ul>
</div>
<div class="md-consent__controls">
  
    
      <button class="md-button md-button--primary">同意</button>
    
    
    
  
    
    
      <button type="reset" class="md-button md-button--primary">拒绝</button>
    
    
  
    
    
    
      <label class="md-button" for="__settings">管理设定</label>
    
  
</div>
          </form>
        </aside>
      </div>
      <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout(function(){document.querySelector("[data-md-component=consent]").hidden=!1},250);var action,form=document.forms.consent;for(action of["submit","reset"])form.addEventListener(action,function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map(function(e){return[e,!0]}))),location.hash="",location.reload()})</script>
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["announce.dismiss", "navigation.tracking", "navigation.tabs", "navigation.sections", "navigation.top", "navigation.footer", "search.suggest", "search.highlight", "search.share", "navigation.expand", "navigation.indexes", "content.tabs.link", "content.tooltips", "content.code.copy", "content.action.edit", "content.action.view", "content.code.annotate"], "search": "../../assets/javascripts/workers/search.74e28a9f.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": {"alias": true, "provider": "mike"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.220ee61c.min.js"></script>
      
        
          <script src="https://Xiaokang2022.github.io/maliang/js/click-colorful.js"></script>
        
      
        
          <script src="https://cdn.jsdelivr.net/gh/Wcowin/Wcowin.github.io@main/docs/javascripts/extra.js"></script>
        
      
        
          <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        
      
        
          <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        
      
        
          <script src="https://cdn.jsdelivr.net/npm/mermaid@10.0.2/dist/add-html-label-6e56ed67.min.js"></script>
        
      
        
          <script src="../../javascripts/extra.js"></script>
        
      
        
          <script src="../../javascripts/mathjax.js"></script>
        
      
        
          <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
        
      
    
  </body>
</html>