## 1.2 术语

术语对齐(alignment)、安全(safety)和保障(assurance)的含义因语境而异。我们使用"对齐"特制意图对齐，即当系统视图按照人类的意图运作时，即视为对齐([Christiano等](https://ai-alignment.com/clarifying-ai-alignment-cec47cd69dd6))。值得注意的是，对齐并不能保证系统实际行为符合预期；例如，系统可能因为能力局限而失效([Ngo等](https://arxiv.org/pdf/2209.00626))。为了简化讨论，我们将意图固定为LLM开发者的意图([Gabriel等](https://link.springer.com/article/10.1007/s11023-020-09539-2),[Ngo等](https://arxiv.org/pdf/2209.00626))，我们认为系统安全程度与其导致非预期有害结果的可能性成反比([Leveson](https://library.oapen.org/bitstream/handle/20.500.12657/26043/1004042.pdf?sequence=1))。该定义具有一定扩展性：既涵盖系统技术特性，也涉及其实际的部署和使用方式([Weidinger等](https://arxiv.org/pdf/2310.11986))，但安全性不涉及**故意作恶**，也不定义什么事危害。对齐可以提高安全性，但是两者并不等同，对齐的AI也可能被用于增强系统危险性(如果开发者有意为之)。最后，“保障”指任何能证明系统安全或对齐的证据提供方式([Ashmore等](https://arxiv.org/pdf/1905.04223))，包括但不限于：科学理解AI的工作原理、通过测试评估AI行为、解释AI的决策逻辑、开发过程是否符合伦理规范([Casper等](https://arxiv.org/pdf/2401.14446))。