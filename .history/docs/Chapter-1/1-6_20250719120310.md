## 轨迹、回报、回合(Trajectories, returns, episodes)

 ![](../img/01/8.png)
 > 图1.6: 根据两种策略所获得轨迹，轨迹在图中用红色虚线标出。

轨迹(trajectory)是一个状态-行动-奖励链。例如，给定一个图1.6所示的策略，代理将会根据以下所示的轨迹进行移动: 

$$s_1\xrightarrow{a_2}s_2\xrightarrow{a_3}s_5\xrightarrow{a_3}s_8\xrightarrow{a_2}s_9.$$

这条轨迹的回报(return)被定义为沿轨迹收集的所有奖励的总和：

$$\mathrm{return}=0+0+0+1=1.$$

