## 2.5 说明贝尔曼方程的例子

接下来我们用两个例子来演示如何写出贝尔曼方程并逐步计算状态值。建议读者仔细阅读以加深对贝尔曼方程的理解。

 ![](../img/02/3.png)
 > 演示贝尔曼方程的示例。本例中的政策是确定性的。

考虑图$2.4$中的第一个例子，其政策是确定性的。接下来，我们写出贝尔曼方程，并根据方程求出各参数。

首先，考虑状态$s_1$。在该策略下，采取行动的概率分别为$\pi(a = a_3|s_1) = 1$和$\pi(a = a_3|s_1) = 0$。状态转移概率为$p(s' = s_3|s_1,a_3) = 1$和$p(s'\neq s_3|s_1,a_3)=0$。奖励概率为
$p(r = 0|s_1, a_3) = 1$ 和 $p(r \neq 0|s_1, a_3) = 0$.将这些值代入$(2.7)$得出。

$$v_\pi(s_1) = 0 + \gamma v_\pi (s_3)$$

有趣的是，尽管$(2.7)$中贝尔曼方程的表达式看似复杂，但其实并不复杂、这个特定状态的表达式非常简单。

同样，可以得出

$$\begin{aligned}
    v_\pi(s_2)=1+\gamma v_\pi(s_4)\\
    v_\pi(s_3)=1+\gamma v_\pi(s_4)\\
    v_\pi(s_4)=1+\gamma v_\pi(s_4)\\
\end{aligned}$$

我们可以根据这些方程求解状态值。由于方程很简单，我们可以手动求解。更复杂的方程将在$2.7$节介绍。在这里，状态值的解法如下:

$$\begin{aligned}
    v_\pi(s_4)=\frac{1}{1-\gamma}\\
    v_\pi(s_3)=\frac{1}{1-\gamma}\\
    v_\pi(s_2)=\frac{1}{1-\gamma}\\
    v_\pi(s_1)=\frac{\gamma}{1-\gamma}\\
\end{aligned}$$

进一步地，如果我们设置$\gamma=0.9$，这时有

$$\begin{aligned}
    v_\pi(s_4)=\frac{1}{1-0.9}=10,\\
    v_\pi(s_3)=\frac{1}{1-0.9}=10,\\
    v_\pi(s_2)=\frac{1}{1-0.9}=10,\\
    v_\pi(s_1)=\frac{0.9}{1-0.9}=9\\
\end{aligned}$$